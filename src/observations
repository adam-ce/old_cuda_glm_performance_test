#test 1
more syntetic, divided into 3 subtests: matrix multiplication, dot products and cross product.
- glm matrix multiplication gets much better after aligning vec4 to 16 bytes

#test 2a and 2b
taken from "real life"
- 2a uses earyly exit from a loop, which is actually more expensive in both, glm and cuda, but glm is ~12.5% behind cuda in most cases.
     at first I didn't use std::srand for a constant initialisation of the random number generator and the timings in 2a were very different.
     The reason was that this early exit was random, so sometimes the time was lower and sometimes higher. ocasioanlly it was very low and
     then glm was faster. generally glm was from 8% - 12% slower.

- in 2b the early exit was removed and glm is about 0.8% - 4.8% behind (depending on the optimisations used). here the std::srand didn't change much.




######  apendix  ######
#### test results glm 0954 ####
### using glm's vanilla const & parameters ###
## vanilla ##
#test 1
CUDA kernel launch with 19532 blocks of 256 threads
time for cuda glm (matrix):         2148 milliseconds
time for cuda helper math (matrix): 655 milliseconds
time for cuda glm (dot):            592 milliseconds
time for cuda helper math (dot):    467 milliseconds
time for cuda glm (cross):          245 milliseconds
time for cuda helper math (cross):  246 milliseconds

#test 2a
time for glm:   488 milliseconds
time for cuda:  416 milliseconds

#test 2b
time for glm:   401 milliseconds
time for cuda:  370 milliseconds

## with vec4 align 16 ##
#test 1
CUDA kernel launch with 19532 blocks of 256 threads
time for cuda glm (matrix):         543 milliseconds
time for cuda helper math (matrix): 661 milliseconds
time for cuda glm (dot):            504 milliseconds
time for cuda helper math (dot):    486 milliseconds
time for cuda glm (cross):          245 milliseconds
time for cuda helper math (cross):  246 milliseconds

#test 2a
time for glm:   467 milliseconds
time for cuda:  416 milliseconds

#test 2b
time for glm:   388 milliseconds
time for cuda:  370 milliseconds

## with vec3 and vec4 align 16 ##
#test 1
CUDA kernel launch with 19532 blocks of 256 threads
time for cuda glm (matrix):         541 milliseconds
time for cuda helper math (matrix): 657 milliseconds
time for cuda glm (dot):            504 milliseconds
time for cuda helper math (dot):    490 milliseconds
time for cuda glm (cross):          217 milliseconds
time for cuda helper math (cross):  246 milliseconds

#test 2a
time for glm:   468 milliseconds
time for cuda:  416 milliseconds

#test 2b
time for glm:   385 milliseconds
time for cuda:  370 milliseconds

## vec4 aligned, m[0][0] * v[0] + .. matrix multiplication ##
#test 1
CUDA kernel launch with 19532 blocks of 256 threads
time for cuda glm (matrix):         540 milliseconds
time for cuda helper math (matrix): 663 milliseconds
time for cuda glm (dot):            493 milliseconds
time for cuda helper math (dot):    481 milliseconds
time for cuda glm (cross):          245 milliseconds
time for cuda helper math (cross):  246 milliseconds

#test 2a
time for glm:   501 milliseconds
time for cuda:  416 milliseconds

#test 2b
time for glm:   403 milliseconds
time for cuda:  370 milliseconds


## vec4 aligned, m.value[0].x * v.x +  .. matrix multiplication ##
#test 1
CUDA kernel launch with 19532 blocks of 256 threads
time for cuda glm (matrix):         546 milliseconds
time for cuda helper math (matrix): 656 milliseconds
time for cuda glm (dot):            489 milliseconds
time for cuda helper math (dot):    496 milliseconds
time for cuda glm (cross):          245 milliseconds
time for cuda helper math (cross):  246 milliseconds

#test 2a
time for glm:   468 milliseconds
time for cuda:  416 milliseconds

#test 2b
time for glm:   378 milliseconds
time for cuda:  370 milliseconds


### almost no const reference in the code ###
## other than that vanilla ##
#test 1
CUDA kernel launch with 19532 blocks of 256 threads
time for cuda glm (matrix):         2148 milliseconds
time for cuda helper math (matrix): 656 milliseconds
time for cuda glm (dot):            591 milliseconds
time for cuda helper math (dot):    482 milliseconds
time for cuda glm (cross):          245 milliseconds
time for cuda helper math (cross):  246 milliseconds

#test 2a
time for glm:   488 milliseconds
time for cuda:  416 milliseconds

#test 2b
time for glm:   413 milliseconds
time for cuda:  370 milliseconds

## with vec4 align 16 ##
#test 1
CUDA kernel launch with 19532 blocks of 256 threads
time for cuda glm (matrix):         540 milliseconds
time for cuda helper math (matrix): 659 milliseconds
time for cuda glm (dot):            501 milliseconds
time for cuda helper math (dot):    488 milliseconds
time for cuda glm (cross):          245 milliseconds
time for cuda helper math (cross):  246 milliseconds

#test 2a
time for glm:   467 milliseconds
time for cuda:  416 milliseconds

#test 2b
time for glm:   374 milliseconds
time for cuda:  370 milliseconds

## with vec3 and vec4 align 16 ##
#test 1
CUDA kernel launch with 19532 blocks of 256 threads
time for cuda glm (matrix):         540 milliseconds
time for cuda helper math (matrix): 655 milliseconds
time for cuda glm (dot):            488 milliseconds
time for cuda helper math (dot):    480 milliseconds
time for cuda glm (cross):          217 milliseconds
time for cuda helper math (cross):  246 milliseconds

#test 2a
time for glm:   468 milliseconds
time for cuda:  416 milliseconds

#test 2b
time for glm:   395 milliseconds
time for cuda:  370 milliseconds

## vec4 aligned, m[0][0] * v[0] + .. matrix multiplication ##
#test 1
CUDA kernel launch with 19532 blocks of 256 threads
time for cuda glm (matrix):         546 milliseconds
time for cuda helper math (matrix): 660 milliseconds
time for cuda glm (dot):            484 milliseconds
time for cuda helper math (dot):    479 milliseconds
time for cuda glm (cross):          245 milliseconds
time for cuda helper math (cross):  246 milliseconds

#test 2a
time for glm:   468 milliseconds
time for cuda:  416 milliseconds

#test 2b
time for glm:   373 milliseconds
time for cuda:  370 milliseconds


## vec4 aligned, m.value[0].x * v.x +  .. matrix multiplication ##
#test 1
CUDA kernel launch with 19532 blocks of 256 threads
time for cuda glm (matrix):         546 milliseconds
time for cuda helper math (matrix): 659 milliseconds
time for cuda glm (dot):            495 milliseconds
time for cuda helper math (dot):    480 milliseconds
time for cuda glm (cross):          245 milliseconds
time for cuda helper math (cross):  246 milliseconds

#test 2a
time for glm:   468 milliseconds
time for cuda:  416 milliseconds

#test 2b
time for glm:   373 milliseconds
time for cuda:  370 milliseconds

## vec4 aligned, __forceinline__
#test 1
CUDA kernel launch with 19532 blocks of 256 threads
time for cuda glm (matrix):         546 milliseconds
time for cuda helper math (matrix): 648 milliseconds
time for cuda glm (dot):            478 milliseconds
time for cuda helper math (dot):    510 milliseconds
time for cuda glm (cross):          246 milliseconds
time for cuda helper math (cross):  246 milliseconds

#test 2a
time for glm:   468 milliseconds
time for cuda:  416 milliseconds

#test 2b
time for glm:   373 milliseconds
time for cuda:  370 milliseconds

























